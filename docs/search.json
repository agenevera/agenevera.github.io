[
  {
    "objectID": "bio.html#bio",
    "href": "bio.html#bio",
    "title": "Genevera Allen",
    "section": "Bio",
    "text": "Bio\nGenevera Allen is a Professor of Statistics at Columbia University. She is also a member of the Center for Theoretical Neuroscience, the Zuckerman Institute for Mind, Brain, and Behavior, and the Irving Institute for Cancer Dynamics. Prior to joining Columbia, Dr. Allen spent fourteen years at Rice University in the Departments of Electrical and Computer Engineering, Statistics, and Computer Science; she was also the Founder and served as the Faculty Director of Rice’s data science education center, informally known as the Rice D2K Lab.\nDr. Allen’s research develops new statistical machine learning tools to help people make reliable discoveries from data. She is known for her methods and theory work in the areas of unsupervised learning, interpretable machine learning, data integration, graphical models, and high-dimensional statistics. Her work is motivated by solving real scientific problems, especially in the areas of neuroscience and bioinformatics.\nDr. Allen is the recipient of several honors including a National Science Foundation Career Award, Rice University’s Duncan Achievement Award for Outstanding Faculty, and in 2014, she was named to the “Forbes ’30 under 30′: Science and Healthcare” list. She is also an elected fellow of the American Statistical Association, Institute of Mathematical Statistics, and International Statistics Institute.\nDr. Allen serves as an Action Editor for the Journal of Machine Learning Research, an Associate Editor for the Journal of the American Statistical Association: Theory and Methods and the Journal of the Royal Statistical Society: Series B, on the editorial board of Foundations and Trends in Machine Learning and Annual Reviews of Statistics and Its Application, and finally as a Series Editor for Springer Texts in Statistics.\nDr. Allen received her Ph.D. in statistics from Stanford University, under the mentorship of Prof. Robert Tibshirani, and her bachelors, also in statistics, from Rice University."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genevera Allen",
    "section": "",
    "text": "Genevera’s Bio\nCurriculum Vitae\nGoogle Scholar Page\n\nContact\nEmail: firstname.lastname@columbia.edu Offices: SSW 1028 & JLG L5-068\n\n\n\n\n\n\nGenevera Allen is a Professor of Statistics at Columbia University. She is also a member of the Center for Theoretical Neuroscience, the Zuckerman Institute for Mind, Brain, and Behavior, and the Irving Institute for Cancer Dynamics. Prior to joining Columbia, Dr. Allen spent fourteen years at Rice University where she founded and directed Rice’s data science education center, informally known as the Rice D2K Lab.\nDr. Allen’s research develops new statistical machine learning tools to help people make reliable discoveries from data.\n\nResearch Interests\n\nUnsupervised Learning\nInterpretable Machine Learning\nGraphical Models\nData Integration\nHigh-Dimensional Statistics\nNeuroscience\nBiomedicine\n\n\n\nOpenings\nWe have openings for postdoctoral scholars, PhD students, and undergraduates. Learn more here."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "September 2024\n\n\nGenevera was selected to give the 2026 IMS Medallion Lecture! Link\n\n\nAugust 2024\n\n\nGroup alumni Lili Zheng starts as an Assistant Professor at University of Illinois Urbana-Champaign!\n\n\nAugust 2024\n\n\nGroup alumni Tiffany Tang starts as an Assistant Professor at the University of Notre Dame!\n\n\nAugust 2024\n\n\nGroup alumni Minjie Wang starts as an Assistant Professor at Binghamton University!\n\n\nJuly 2024\n\n\nTarek Zikry joins the group as a postdoctoral scholar. Welcome Tarek!\n\n\nJuly 2024\n\n\nGenevera officially joins Columbia as a Professor of Statistics and member of the Center for Theoretical Neuroscience at the Zuckerman Institute for Mind, Brain, and Behavior (Profile) and the Irving Institute for Cancer Dynamics (News Story).\n\n\nMay 2024\n\n\nGenevera is named an IMS Fellow! Link"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Statistical Machine Learning is a PhD-level course on statistical and probabilistic foundations of machine learning. We will cover statistical machine learning methods, theory, and inference as well as how to apply such methods to real problems. We study both the foundations and modern methods in this field. Our goals are to understand statistical machine learning, to begin research that makes contributions to this field, and to develop good practices for building and applying these models in practice.  Lectures: MW 2:40pm - 3:55pm"
  },
  {
    "objectID": "teaching.html#columbia-courses",
    "href": "teaching.html#columbia-courses",
    "title": "Teaching",
    "section": "",
    "text": "Statistical Machine Learning is a PhD-level course on statistical and probabilistic foundations of machine learning. We will cover statistical machine learning methods, theory, and inference as well as how to apply such methods to real problems. We study both the foundations and modern methods in this field. Our goals are to understand statistical machine learning, to begin research that makes contributions to this field, and to develop good practices for building and applying these models in practice.  Lectures: MW 2:40pm - 3:55pm"
  },
  {
    "objectID": "teaching.html#data-science-machine-learning-education",
    "href": "teaching.html#data-science-machine-learning-education",
    "title": "Teaching",
    "section": "Data Science & Machine Learning Education",
    "text": "Data Science & Machine Learning Education\n\n\n\n\n\nGenevera Allen is a sought after educator in machine learning and data science. She has developed and taught a variety of machine learning courses as well as several novel experiential learning courses in data science. These include an interdisciplinary data science capstone program where students work on real-world challenges and data sets from a variety of industries and disciplines.\n\n\n\nRice Center for Transforming Data to Knowledge (Rice D2K Lab)\n\n\nIn 2018, Genevera Allen founded and served as the Faculty Director of Rice’s data science education center, informally known as the Rice D2K Lab. The D2K Lab is a hub for data science education, providing students with engagement, enrichment, and experiential learning opportunities by connecting them with real-world data science challenges from companies, community organizations, and researchers. As part of these efforts, Genevera developed several new experiential learning courses including a novel data science capstone program that serves as the cornerstone of Rice’s data science undergraduate and masters degree programs.\n\n\n\n\n\n\nEducation Research\n\n\nKey Publications:\n\n\nG. I. Allen, “Experiential Learning in Data Science: Developing an Interdisciplinary, Client-Sponsored Capstone Program”, In Proceedings of the 52nd ACM Technical Symposium on Computer Science Education (SIGCSE), 2021. link\nA. Barman, S. Chen, A. Chang and G. I. Allen, “Experiential Learning in Data Science Through a Novel Client-Facing Consulting Course”, In IEEE Frontiers in Education, 1-9, 2022. link"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Genevera’s group develops new statistical machine learning tools to help people make reliable discoveries from large and complex data sets, especially in neuroscience and biomedicine.\nView Full List of Publications via Google Scholar"
  },
  {
    "objectID": "research.html#data-driven-discovery",
    "href": "research.html#data-driven-discovery",
    "title": "Research",
    "section": "",
    "text": "Genevera’s group develops new statistical machine learning tools to help people make reliable discoveries from large and complex data sets, especially in neuroscience and biomedicine.\nView Full List of Publications via Google Scholar"
  },
  {
    "objectID": "research.html#research-areas",
    "href": "research.html#research-areas",
    "title": "Research",
    "section": "Research Areas",
    "text": "Research Areas\n\nStatistical Machine Learning\n\nGraphical Models\n\n\n\n\n\nWe develop new types of probabilistic graphical models and graph learning strategies for representing, discovering, and visualizing relationships in large data sets. Our work includes developing new classes of graphical models for diverse data types and multi-modal data as well as new graph learning strategies to tackle challenges encountered in neuroscience and beyond.\n\n\nKey Publications:\n\n\nE. Yang, P. Ravikumar, G. I. Allen, and Z. Liu, “Graphical Models via Univariate Exponential Family Distributions”, Journal of Machine Learning Research, 16:3813-3847, 2015. link\nE. Yang, Y. Baker, P. Ravikumar, G. I. Allen, and Z. Liu, “Mixed Graphical Models via Exponential Families”, In Artificial Intelligence and Statistics (AISTATS), oral presentation, 2014. link\nL. Zheng and G. I. Allen, “Graphical Model Inference with Erosely Measured Data”, (To Appear) Journal of American Statistical Association: Theory & Methods, arXiv:2210.11625, 2023. link\nM. Wang and G. I. Allen, “Thresholded Graphical Lasso Adjusts for Latent Variables”, Biometrika, 110:3, 681-697, 2023. link\nG. Vinci, G. Dasarathy, and G. I. Allen, “Graph Quilting: Graphical Model Selection from Partially Observed Covariances”, arXiv:1912.05573, 2020. link\nE. Yang, P. Ravikumar, G. I. Allen, and Z. Liu, “On Poisson Graphical Models”, In Advances in Neural Information Processing Systems (NeurIPS), 2013. link\nA. Chang and G. I. Allen, “Subbotin Graphical Models for Extreme Value Dependencies with Applications to Functional Neuronal Connectivity”, Annals of Applied Statistics, 17:3, 2364-2386, 2023. link\n\n\n\n\n\n\nData Integration\n\n\n\n\n\nLarge data sets are often diverse, with multiple types of features measured on the same set of subjects or observations. We have developed a variety of interpretable machine learning techniques for discovering joint patterns in this so-called mixed multi-modal data.\n\n\nKey Publications:\n\n\nT. M. Tang and G. I. Allen, “Integrated Principal Components Analysis”, Journal of Machine Learning Research, 22:198, 1-71, 2021. link\nM. Wang and G. I. Allen, “Integrative Generalized Convex Clustering Optimization and Feature Selection for Mixed Multi-View Data”, Journal of Machine Learning Research, 22:1-73, 2021. link\nY. Baker, T. M. Tang, and G. I. Allen, “Feature Selection for Data Integration with Mixed Multiview Data”, Annals of Applied Statistics, 14:4, 1676-1698, 2020. link\nJ. Liu, L. Zheng, Z. Zhang, and G. I. Allen, “Joint Semi-Symmetric Tensor PCA for Integrating Multi-modal Populations of Networks”, arXiv:2312.14416, 2023. link\nY. W. Wan, G. I. Allen, and Z. Liu, “TCGA2STAT: Simple TCGA Data Access for Integrated Statistical Analysis in R”, Bioinformatics, 32:6, 952-954, 2016. link\nE. Yang, Y. Baker, P. Ravikumar, G. I. Allen, and Z. Liu, “Mixed Graphical Models via Exponential Families”, In Artificial Intelligence and Statistics (AISTATS), oral presentation, 2014. [link](https://proceedings.mlr.press/v33/yang14a.pdf\n\n\n\n\n\n\nClustering\n\n\n\n\n\nClustering seeks to find groups in large data sets. We have developed several convex clustering approaches that offer reliable, principled, and flexible strategies along with built-in visualizations for clustering.\n\n\nKey Publications:\n\n\nE. C. Chi, G. I. Allen, and R. Baraniuk, “Convex Biclustering”, Biometrics, 73:1, 10-19, 2017. link\nM. Weylandt, J. Nagorski, and G. I. Allen, “Dynamic Visualization and Fast Computation for Convex Clustering via Algorithmic Regularization”, Journal of Computational and Graphical Statistics, 29:1, 87-96, 2020. link\nM. Wang and G. I. Allen, “Integrative Generalized Convex Clustering Optimization and Feature Selection for Mixed Multi-View Data”, Journal of Machine Learning Research, 22:1-73, 2021. link\nY. Baker, T. M. Tang, and G. I. Allen, “Feature Selection for Data Integration with Mixed Multiview Data”, Annals of Applied Statistics, 14:4, 1676-1698, 2020. link\nL. Gan and G. I. Allen, “Fast and Interpretable Consensus Clustering via Minipatch Learning”, PLoS Computational Biology, 18:10, e1010577, 2022. link\nM. Wang, T. Yao, and G. I. Allen, “Supervised Convex Clustering”, Biometrics, 79:4, 3846-3858, 2023. link\nL. Zheng, A. Chang, and G. I. Allen, “Cluster Quilting: Spectral Clustering for Patchwork Learning”, arXiv:2406.13833, 2024. link\n\n\n\n\n\n\nDimension Reduction\n\n\n\n\n\nDimension reduction techniques are used for visualizing, exploring, and discovering patterns in large data sets. We have developed many dimension reduction techniques for complex and structured data; these include sparse tensor decompositions and generalizations of PCA for structured or multi-modal data.\n\n\nKey Publications:\n\n\nG. I. Allen, L. Grosenick and J. Taylor, “A Generalized Least Squares Matrix Decomposition”, Journal of the American Statistical Association: Theory and Methods, 109:505, 145-159, 2014. link\nG. I. Allen, “Sparse Higher-Order Principal Components Analysis”, In Artificial Intelligence and Statistics (AISTATS), 27-36, 2012. link\nT. M. Tang and G. I. Allen, “Integrated Principal Components Analysis”, Journal of Machine Learning Research, 22:198, 1-71, 2021. link\nG. I. Allen, and M. Weylandt, “Sparse and Functional Principal Components Analysis”, In Proceedings of the IEEE Data Science Workshop, 2019. link\nG. I. Allen and M. Maletic-Savatic, “Sparse Non-negative Generalized PCA with Applications to Metabolomics”, Bioinformatics, 27:21, 3029-3035, 2011. link\nJ. Liu, L. Zheng, Z. Zhang, and G. I. Allen, “Joint Semi-Symmetric Tensor PCA for Integrating Multi-modal Populations of Networks”, arXiv:2312.14416, 2023. link\n\n\n\n\n\n\nSparsity & High-Dimensional Statistics\n\n\n\n\n\nMuch of our research lies in the area of high-dimensional statistics, where the number of features exceeds the number of samples. A major focus in this area is on sparsity and structured sparsity to enhance feature selection and interpretability.\n\n\nKey Publications:\n\n\nF. Campbell and G. I. Allen, “Within Group Variable Selection through the Exclusive Lasso”, Electronic Journal of Statistics, 11:2, 4220-4257, 2017. link\nG. I. Allen, “Automatic Feature Extraction via Weighted Kernels and Regularization”, Journal of Computational and Graphical Statistics, 22:2, 284-299, 2013. link\nY. Baker, T. M. Tang, and G. I. Allen, “Feature Selection for Data Integration with Mixed Multiview Data”, Annals of Applied Statistics, 14:4, 1676-1698, 2020. link\nA. Chang, M. Wang, and G. I. Allen, “Sparse Regression for Extreme Values”, Electronic Journal of Statistics, 15:2, 5995-6035, 2021. link\nY. Hu, E. C. Chi, and G. I. Allen, “ADMM Algorithmic Regularization Paths for Sparse Statistical Learning”, In Splitting Methods in Communication and Imaging, Science and Engineering, R. Glowinski, W. Yin, and S. Osher (eds), Springer, 433-459, 2016. link\n\n\n\n\n\n\nTensors\n\n\n\n\n\nDirectly working with tensor, or multi-way array, data yields many computational and statistical advantages. Our work has focused on developing interpretable tensor decomposition strategies with applications in neuroscience, chemometrics, and genomics.\n\n\nKey Publications:\n\n\nG. I. Allen, “Sparse Higher-Order Principal Components Analysis”, In Artificial Intelligence and Statistics (AISTATS), 27-36, 2012. link\nG. I. Allen, “Multi-way Functional Principal Components Analysis”, In IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, 2013. link\nZ. Zhang, G. I. Allen, H. Zhu, D. Dunson, “Tensor Network Factorizations: Relationships between Human Brain Structural Connectomes and Traits”, NeuroImage, 197:330-343, 2019. link\nJ. Liu, L. Zheng, Z. Zhang, and G. I. Allen, “Joint Semi-Symmetric Tensor PCA for Integrating Multi-modal Populations of Networks”, arXiv:2312.14416, 2023. link\nK. Geyer, F. Campbell, A. Chang, J. Magnotti, M. Beauchamp, G. I. Allen, “Interpretable Visualization and Higher-Order Dimension Reduction for ECoG Data”, In Proceedings of the The International Workshop on Big Data Reduction held with the 2020 IEEE International Conference on Big Data, 2020. link\n\n\n\n\n\n\nEnsemble Learning\n\n\n\n\n\nRecently, we have begun developing new computationally efficient ensemble learning strategies called minipatch learning that also lead to improved statistical properties and interpretability.\n\n\nKey Publications:\n\n\nT. Yao, D. LeJeune, H. Javadi, R. G. Baraniuk, and G. I. Allen, “Minipatch Learning as Implicit Ridge-Like Regularization”, In IEEE International Conference on Big Data and Smart Computing (BigComp), 2021. link\nM. T. Toghani and G. I. Allen, “MP-Boost: Minipatch Boosting via Adaptive Feature and Observation Sampling”, In IEEE International Conference on Big Data and Smart Computing (BigComp), 2021. link\nL. Gan and G. I. Allen, “Fast and Interpretable Consensus Clustering via Minipatch Learning”, PLoS Computational Biology, 18:10, e1010577, 2022. link\nL. Gan, L. Zheng, and G. I. Allen, “Model-Agnostic Confidence Intervals for Feature Importance: A Fast and Powerful Approach Using Minipatch Ensembles”, arXiv:2206.02088, 2022. link\nT. Yao, M. Wang, and G. I. Allen, “Fast and Accurate Graph Learning for Huge Data via Minipatch Ensembles”, arXiv:2110.12067, 2021. link\n\n\n\n\n\n\nQuilting & Patchwork Learning\n\n\n\n\n\nIn neuroscience, data integration, causal panel data and more, we often observe data in patches or blocks with huge portions of data that is not missing at random. We recently have developed new unsupervised approaches in this patchwork learning setting.\n\n\nKey Publications:\n\n\nG. Vinci, G. Dasarathy, and G. I. Allen, “Graph Quilting: Graphical Model Selection from Partially Observed Covariances”, arXiv:1912.05573, 2020. link\nA. Chang, L. Zheng and G. I. Allen, “Low-Rank Covariance Completion for Graph Quilting with Applications to Functional Connectivity”, arXiv:2209.08273, 2022. link\nL. Zheng and G. I. Allen, “Graphical Model Inference with Erosely Measured Data”, (To Appear) Journal of American Statistical Association: Theory & Methods, arXiv:2210.11625, 2023. link\nA. Chang, L. Zheng, G. Dasarthy, G. I. Allen, ”Nonparanormal Graph Quilting with Applications to Calcium Imaging”, Stat, 12:1, e623, 2023. link\nL. Zheng, A. Chang, and G. I. Allen, “Cluster Quilting: Spectral Clustering for Patchwork Learning”, arXiv:2406.13833, 2024. link\n\n\n\n\n\n\n\nNeuroscience\n\nConnectomics\n\n\n\n\n\nConnectomics seeks to understand how brain regions or neurons are structurally and functionally connected. Our research has focused on two aspects: developing new techniques to discover patterns in connectomics data and developing new techniques to learn functional connections from neural activity.\n\n\nKey Publications:\n\n\nM. Narayan and G. I. Allen, “Mixed Effects Models for Resampled Network Statistics Improves Statistical Power to Find Differences in Multi-Subject Functional Connectivity” Frontiers in Neuroscience, 10:108, 2016. link\nS. Tomson, M. Narayan, G. I. Allen, D. Eagleman, “Neural Networks of Synesthesia”, Journal of Neuroscience, 33:35, 14098-14106, 2013. link\nS. Tomson, M. Schreiner, M. Narayan, T. Rosser; N. Enrique, A. J. Silva, G. I. Allen, S. Y. Bookheimer, and C. Bearden, “Resting state functional MRI reveals abnormal network connectivity in Neurofibromatosis 1”, Human Brain Mapping, 36:11, 4566-4581, 2015. link\nM. Wang and G. I. Allen, “Thresholded Graphical Lasso Adjusts for Latent Variables”, Biometrika, 110:3, 681-697, 2023. link\nG. Vinci, G. Dasarathy, and G. I. Allen, “Graph Quilting: Graphical Model Selection from Partially Observed Covariances”, arXiv:1912.05573, 2020. link\nA. Chang, L. Zheng and G. I. Allen, “Low-Rank Covariance Completion for Graph Quilting with Applications to Functional Connectivity”, arXiv:2209.08273, 2022. link\nA. Chang and G. I. Allen, “Subbotin Graphical Models for Extreme Value Dependencies with Applications to Functional Neuronal Connectivity”, Annals of Applied Statistics, 17:3, 2364-2386, 2023. link\nT. Yao, M. Wang, and G. I. Allen, “Fast and Accurate Graph Learning for Huge Data via Minipatch Ensembles”, arXiv:2110.12067, 2021. link\nA. Chang, T. Yao, and G. I. Allen, “Graphical Models and Dynamic Factor Models for Modeling Functional Brain Connectivity”, In Proceedings of the IEEE Data Science Workshop, 2019. link\nZ. Zhang, G. I. Allen, H. Zhu, D. Dunson, “Tensor Network Factorizations: Relationships between Human Brain Structural Connectomes and Traits”, NeuroImage, 197:330-343, 2019. link\n\n\n\n\n\n\nPattern Discovery\n\n\n\n\n\nOur research seeks to discover scientifically interpretable patterns from large-scale neuroscience data using a combination of statistical and interpretable machine learning approaches. We have applied our techniques to many types of macro and micro-scale recording and imaging technologies including MRI, functional MRI, diffusion imaging, EEG, PET, ECoG, calcium imaging, spike trains, and many more.\n\n\nKey Publications:\n\n\nZ. Zhang, G. I. Allen, H. Zhu, D. Dunson, “Tensor Network Factorizations: Relationships between Human Brain Structural Connectomes and Traits”, NeuroImage, 197:330-343, 2019. link\nK. Geyer, F. Campbell, A. Chang, J. Magnotti, M. Beauchamp, G. I. Allen, “Interpretable Visualization and Higher-Order Dimension Reduction for ECoG Data”, In Proceedings of the The International Workshop on Big Data Reduction held with the 2020 IEEE International Conference on Big Data, 2020. link\nJ. Liu, L. Zheng, Z. Zhang, and G. I. Allen, “Joint Semi-Symmetric Tensor PCA for Integrating Multi-modal Populations of Networks”, arXiv:2312.14416, 2023. link\nG. I. Allen, and M. Weylandt, “Sparse and Functional Principal Components Analysis”, In Proceedings of the IEEE Data Science Workshop, 2019. link\nY. Hu and G. I. Allen, “Local-Aggregate Modeling for Big-Data via Distributed Optimization: Applications to Neuroimaging”, Biometrics, 71:4, 905-917, 2015. link\n. T. Yao, E. M. Sweeney, J. Nagorski, J. Shulman, and G. I. Allen, “Quantifying cognitive resilience in Alzheimer’s Disease: The Alzheimer’s Disease Cognitive Resilience Score”, PLoS One, 15:11, e0241707, 2020. link\n\n\n\n\n\n\n\nAI Ethics\n\nInterpretable Machine Learning\n\n\n\n\n\nRecently, we have begun working on statistical challenges in interpretable machine learning. Our focus is on developing validation and uncertainty quantification strategies for machine learning interpretations including feature importance and unsupervised discoveries.\n\n\nKey Publications:\n\n\nG. I. Allen, L. Gan, L. Zheng, ”Interpretable Machine Learning for Discovery: Statistical Challenges and Opportunities”, Annual Review of Statistics and its Application, 11:97-121, 2024. link\nL. Gan, L. Zheng, and G. I. Allen, “Model-Agnostic Confidence Intervals for Feature Importance: A Fast and Powerful Approach Using Minipatch Ensembles”, arXiv:2206.02088, 2022. link\n\n\n\n\n\n\nAlgorithmic Fairness\n\n\n\n\n\nMachine learning algorithms can often inadvertently discriminate against certain subgroups by exacerbating subtle biases in historic data. Our recent work in the area of algorithmic fairness has sought to develop ways to audit and interpret bias mitigation strategies in machine learning.\n\n\nKey Publications:\n\n\nC. O. Little, M. Weylandt, and G. I. Allen, “To the Fairness Frontier and Beyond: Identifying, Quantifying, and Optimizing the Fairness-Accuracy Pareto Frontier”, arXiv:2206.00074, 2022. link\nC. O. Little, D. H. Lina, and G. I. Allen, “Fair Feature Importance Scores for Interpreting Tree-Based Methods and Surrogates”, (To Appear), Transactions on Machine Learning Research, arXiv:2310.04352, 2024. link\nM. Navarro, C. O. Little, G. I. Allen, and S. Segarra, “Data Augmentation via Subgroup Mixup for Improving Fairness”, In IEEE International Conference on Acoustics, Speech, and Signal Processing, 7350-7354, 2024. link\n\n\n\n\n\n\n\nBiomedicine\n\nGenomics\n\n\n\n\n\nMuch of our research program has been inspired by challenges in high-throughput genomics and multi-omics data. We have developed new statistical machine learning techniques and applied these to study genomic mechanisms in cancer and neurological diseases.\n\n\nKey Publications:\n\n\nY. W. Wan, G. I. Allen, and Z. Liu, “TCGA2STAT: Simple TCGA Data Access for Integrated Statistical Analysis in R”, Bioinformatics, 32:6, 952-954, 2016. link\nG. I. Allen and Z. Liu, “A Local Poisson Graphical Model for Inferring Networks from Next Generation Sequencing Data”, IEEE Transactions on NanoBioscience, 12:3, 1-10, 2013. link\nG. I. Allen and M. Maletic-Savatic, “Sparse Non-negative Generalized PCA with Applications to Metabolomics”, Bioinformatics, 27:21, 3029-3035, 2011. link\nL. Gan and G. I. Allen, “Fast and Interpretable Consensus Clustering via Minipatch Learning”, PLoS Computational Biology, 18:10, e1010577, 2022. link\nL. Gan, G. Vinci, and G. I. Allen, “Correlation Imputation for Single Cell RNA-seq”, Journal of Computational Biology, 29:5, 465-482, 2022. link"
  },
  {
    "objectID": "group.html",
    "href": "group.html",
    "title": "Group",
    "section": "",
    "text": "Genevera Allen"
  },
  {
    "objectID": "group.html#pi",
    "href": "group.html#pi",
    "title": "Group",
    "section": "",
    "text": "Genevera Allen"
  },
  {
    "objectID": "group.html#postdocs",
    "href": "group.html#postdocs",
    "title": "Group",
    "section": "Postdocs",
    "text": "Postdocs\n\n\n\n\n\n Tarek Zikry, PhD UNC Chapel Hill, Biostatistics, 2024."
  },
  {
    "objectID": "group.html#phd-students",
    "href": "group.html#phd-students",
    "title": "Group",
    "section": "PhD Students",
    "text": "PhD Students\n\n\n\n\n\n Camille Little, PhD Candidate Electrical & Computer Engineering, Rice University."
  },
  {
    "objectID": "group.html#undergraduate-students",
    "href": "group.html#undergraduate-students",
    "title": "Group",
    "section": "Undergraduate Students",
    "text": "Undergraduate Students\n\n\n\n\n\n Eric Chen, Class of 2025, Columbia."
  },
  {
    "objectID": "group.html#research-group-meetings",
    "href": "group.html#research-group-meetings",
    "title": "Group",
    "section": "Research Group Meetings",
    "text": "Research Group Meetings\nStatistical Machine Learning research group meetings will take place on Wednesdays from 4:00pm - 5:30pm in SSW 1025 in Fall 2024. Email Genevera if you’d like to be added to our research group meeting list!"
  },
  {
    "objectID": "group.html#openings",
    "href": "group.html#openings",
    "title": "Group",
    "section": "Openings",
    "text": "Openings\nInterested in joining the Statistical Machine Learning group? There are openings for a postdoctoral scholar starting anytime in 2025. Learn more here. Current Columbia graduate or undergraduate students interested in joining the group should email Genevera to learn more."
  },
  {
    "objectID": "group.html#alumni",
    "href": "group.html#alumni",
    "title": "Group",
    "section": "Alumni",
    "text": "Alumni\n\nPostdoc Alumni\n\n\n\n\n\n Lili Zheng. Now an Assistant Professor at UIUC.\n\n\n\n\n\n\n\n Giuseppe Vinci. Now an Assistant Professor at the University of Notre Dame.\n\n\n\n\n\n\n\n Elizabeth Sweeney. Now at Corteva Agriscience.\n\n\n\n\nPhD Alumni\n\n\n\n\n\n Andersen Chang. Now at Baylor College of Medicine.\n\n\n\n\n\n\n\n Luqin Gan. Now at HAP Capital.\n\n\n\n\n\n\n\n Tianyi Yao. Now at Microsoft.\n\n\n\n\n\n\n\n Minjie Wang. Now an Assistant Professor at Binghamton University.\n\n\n\n\n\n\n\n Frederick Campbell. Now at Microsoft.\n\n\n\n\n\n\n\n John Nagorski. Now at Encino Energy.\n\n\n\n\n\n\n\n Yulia Hendrix. Now at Iodine Software.\n\n\n\n\n\n\n\n Yue Hu. Now at Liberty Mutual.\n\n\n\n\n\n\n\n Manjari Narayan. Now at Speculative Technologies.\n\n\n\n\nUndergraduate Alumni\n\nChuk Uzowihe.\nZach Rewolinski. Now a Berkeley Statistics PhD student.\nQuan Le. Now a Yale Statistics PhD student.\nNathan Powell.\nTiffany Tang. Now an Assistant Professor at Notre Dame.\nAlex Hayes.\nWilliam Deadrick.\nAndrew Dumit.\nRaymond Cano.\nTianyi Yao.\nJoshua Lipshultz.\nEmily Burnett.\nJake Kornblau.\nLinda Zheng.\nQijia Jiang.\nConnor Barnhill.\nJessica Gan."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Check out our group’s software on Github"
  },
  {
    "objectID": "software.html#highlighted-software",
    "href": "software.html#highlighted-software",
    "title": "Software",
    "section": "Highlighted Software",
    "text": "Highlighted Software\n\n\n clustRviz enables fast computation and easy visualization of convex clustering and biclustering solution paths.\n\n\n TCGA2STAT allows users to easily download The Cancer Genome Atlas (TCGA) data directly into a format ready for integrative statistical analysis in R or Python."
  }
]